{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88f9a23-419b-429e-b8cb-41501f7f377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mouad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mouad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required libs and packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ac13e2-c533-4041-96cb-9780c0a4b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "context = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241d491a-80ca-4c4c-b729-4415643921bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Testing:\n",
    "    def __init__(self):\n",
    "        # Load the intent file\n",
    "        self.intents = json.loads(open(\"./chatbot-code/intents.json\").read())\n",
    "\n",
    "        data = pickle.load(open(\"training_data\", \"rb\"))\n",
    "        self.words = data[\"words\"]\n",
    "        self.classes = data[\"classes\"]\n",
    "        self.model = load_model(\"chatbot_model.h5\")\n",
    "        self.ERROR_THRESHOLD = 0.5\n",
    "        self.ignore_words = list(\"!@#$%^&*?\")\n",
    "\n",
    "    def clean_up_sentence(self, sentence):\n",
    "        # Tokenize each sentence (user's query)\n",
    "        sentence_words = word_tokenize(sentence.lower())\n",
    "        sentence_words = list(map(lemmatizer.lemmatize, sentence_words))\n",
    "\n",
    "        sentence_words = list(filter(lambda x: x not in self.ignore_words))\n",
    "\n",
    "        return set(sentence_words)\n",
    "\n",
    "    def wordvector(self, sentence):\n",
    "        cv = CountVectorizer(tokenizer=lambda txt: txt.split())\n",
    "        sentence_words = \" \".join(self.clean_up_sentence(sentence))\n",
    "\n",
    "        words = \" \".join(self.words)\n",
    "\n",
    "        vectorize = cv.fit([words])\n",
    "\n",
    "        word_vector = vectorize.transform(\n",
    "            [sentence_words]).toarray().tolist()[0]\n",
    "\n",
    "        return (np.array(word_vector))\n",
    "    \n",
    "    def classify(self,sentence):\n",
    "        # Predict to which class  (tag)  user's query belongs to\n",
    "        \n",
    "        results = self.model.predict(np.array([self.wordvector(sentence)]))[0]\n",
    "        \n",
    "        # Store the class and probability of chat class\n",
    "        results = list(map(lambda x: [x[0], x[1]],enumerate(results)))\n",
    "        \n",
    "        # Accept those class probability which are greater then threshold value 0.5\n",
    "        \n",
    "        results = list(filter(lambda x: x[1]> self.ERROR_THRESHOLD, results))\n",
    "        \n",
    "        results.sort(key=lambda x: x[1] , reverse = True)\n",
    "        \n",
    "        return_lists = []\n",
    "        \n",
    "        for i in results:\n",
    "            return_lists.append((self.classes[i[0]], str(i[1])))\n",
    "            \n",
    "        return return_lists\n",
    "    \n",
    "    def results(self,sentence,userID):\n",
    "        \n",
    "        if sentence.isdecimal():\n",
    "            if context[userID] == \"historydetails\":\n",
    "                return self.classify(\"ordernumber\")\n",
    "        return self.classify(sentence)\n",
    "    \n",
    "    \n",
    "    def response(self,sentence,userID=\"Mouad\"):\n",
    "        \n",
    "        results = self.results(sentence,userID)\n",
    "        print(sentence,results)\n",
    "        \n",
    "        # Store random response to the query\n",
    "        \n",
    "        ans=\"\"\n",
    "        if results:\n",
    "            for i in self.intents[\"intents\"]:\n",
    "                # Check if tag  == query's class\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    if  \"set\" in i and not \"filter\" in i :\n",
    "                        context[userID] = i['set']\n",
    "                    if not 'filter' in i :\n",
    "                        ans = random.choice(i[\"responses\"])\n",
    "                    if userID in context and 'filter' in i and i['filter']==context[userID]:\n",
    "                        if \"set\" in i:\n",
    "                            context[userID] = i[\"set\"]\n",
    "                            ans = random.choice(i['responses'])\n",
    "        results.pop(0)\n",
    "        # If ans contains some value then return response to user's query else return some message\n",
    "        \n",
    "        return ans if ans != \"\" else \"Sorry couldn't understand , I m still learning.\\nYou can train me by provinding more data.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
